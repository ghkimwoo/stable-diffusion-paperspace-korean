{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfKvWAVnz8OB",
    "tags": []
   },
   "source": [
    "# AUTOMATIC1111의 Stable Diffusion WebUI 실행 한국어용\n",
    "\n",
    "https://github.com/AUTOMATIC1111/stable-diffusion-webui\n",
    "\n",
    "https://github.com/Engineer-of-Stuff/stable-diffusion-paperspace 을 기반으로 작성함.\n",
    "\n",
    "**가이드**\n",
    "- [Getting started on Paperspace](https://github.com/Engineer-of-Stuff/stable-diffusion-paperspace/blob/main/Docs/Paperspace%20Guide%20for%20Retards.md)\n",
    "- [Using the WebUI](https://rentry.org/voldy)\n",
    "- [Using the Inpainter](https://rentry.org/drfar)\n",
    "- [Textual Inversion](https://rentry.org/aikgx)\n",
    "- [Crowd-Sourced Prompts](https://lexica.art/)\n",
    "- [Artist Name Prompts](https://sgreens.notion.site/sgreens/4ca6f4e229e24da6845b6d49e6b08ae7?v=fdf861d1c65d456e98904fe3f3670bd3)\n",
    "- [Stable Diffusion Models](https://cyberes.github.io/stable-diffusion-models)\n",
    "- [Textual Inversion Models](https://cyberes.github.io/stable-diffusion-textual-inversion-models/)\n",
    "- [Have I Been Trained?](https://haveibeentrained.com/)\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 설치 및 설정\n",
    "\n",
    "SD를 실행할 때마다 모든 것을 다시 설치해야합니다. 이미 다운로드 된 경우 종속성이 자동 업데이트 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**파일의 저장 위치**\n",
    "\n",
    "`/storage/`는 계정의 모든 컴퓨터에서 공유되는 영구 저장소입니다. 당신의 컴퓨터에 모두 저장됩니다.\n",
    "\n",
    "`/notebooks/`은 이 노트북 전용 저장소입니다. 이 위치는 컴퓨터로 복사해야 하므로 용량이 크면 시작/중지 시간이 늘어날 수 있습니다. \n",
    "이를 방지하려면 대용량 파일은 `/storage/`에 넣으세요.\n",
    "\n",
    "`/tmp/` <mark style=\"background-color:lime\">은 임시 위치입니다, 그러므로 세션이 종료될 시 해당 위치의 모든 파일은 삭제됩니다.</mark>\n",
    "\n",
    "<br>\n",
    "\n",
    "<mark style=\"background-color: #ff780082\">저장소 문제가 있는 경우</mark>, `repo_storage_dir`를 `/tmp/stable-diffusion`로 설정하세요. `symlink_to_notebooks`가 `/notebooks/`로 연결되도록 `True`로 설정 되어 있는지 확인하세요.\n",
    "\n",
    "<br>\n",
    "\n",
    "<mark>올바른 섹션의 댓글을 실행 완료하지 않고 다른 댓글을 실행하는 경우 노트북이 정상 작동하지 않습니다!</mark>\n",
    "\n",
    "원하는 섹션을 선택하고 `ctrl + /` 를 눌러 댓글을 취소합니다. 여기서 설정을 변경한 경우 이 셀을 다시 실행하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 저장할 위치를 선택하세요\n",
    "\n",
    "# 무료 등급\n",
    "# model_storage_dir = '/tmp/stable-diffusion-models'\n",
    "\n",
    "# 유료 등급\n",
    "model_storage_dir = '/storage/models'\n",
    "\n",
    "\n",
    "\n",
    "# 경로 설정(선택 사항)\n",
    "repo_storage_dir = '/storage/stable-diffusion'         # Stable Diffusion 관련 파일을 저장할 위치.\n",
    "\n",
    "export_storage_dir = '/notebooks/exports'              # 생성된 이미지를 내보낼 위치.\n",
    "\n",
    "pip_cache_dir = None                                   # Installer가 pip wheels를 캐시할 수 있으므로 다시 다운로드할 필요가 없습니다.\n",
    "                                                       # 위치를 입력하세요. '/storage/pip/cache'로 설정하는 것이 좋습니다.\n",
    "\n",
    "\n",
    "# 기타 설정(선택 사항)\n",
    "# 원하지 않는 경우 변경하지 않아도 됩니다.\n",
    "\n",
    "symlink_to_notebooks = True                            # 다시 /노트북/으로 돌아가는 심볼릭 링크를 생성합니다.\n",
    "\n",
    "activate_xformers = True                               # 사전 빌드된 휠을 사용하여 엑스포머 최적화를 활성화합니다.\n",
    "                                                       # True로 설정하면 환경/기계가 자동으로 xformers에 맞게 설정됩니다.\n",
    "\n",
    "link_novelai_anime_vae = True                          # animevae.pt를 각 NovelAI 모델에 연결할 수 있도록 설정합니다.\n",
    "                                                       # NovelAI 모델과 하이퍼네트워크를 모두 다운로드한 경우 True로 설정합니다.\n",
    "\n",
    "activate_deepdanbooru = False                          # DeepDanbooru 활성화 및 설치 -> https://github.com/KichangKim/DeepDanbooru\n",
    "\n",
    "activate_medvram = False                               # medvram 옵션을 활성화합니다.\n",
    "                                                       # 일부 속도를 희생하여 VRAM 사용량을 줄이는 모델 최적화입니다.\n",
    "                                                       # VRAM이 많은 경우 False로 설정합니다.\n",
    "\n",
    "disable_pickle_check = False                           # 모델 파일에서 예기치 않은 데이터에 대한 자동 검사를 비활성화합니다. (권장하지 않음)\n",
    "                                                       # 검사를 비활성화할 이유가 없는 한 이 설정을 False로 둡니다.\n",
    "\n",
    "gradio_port = False                                    # 특정 포트에서 Gradio 실행. Gradio가 포트를 선택하도록 하려면 False로 설정합니다.\n",
    "                                                       # 이렇게 하면 온라인 Gradio 앱 모드가 비활성화되며 로컬 네트워크에서만 액세스할 수 있습니다.\n",
    "\n",
    "gradio_auth = False                                    # gradio_auth 및 insecure-extension-access 옵션을 활성화합니다.\n",
    "                                                       # 사용하려면 사용자 이름:비밀번호(예: \"me:password\")로 설정합니다.\n",
    "\n",
    "search_paperspace_datasets = True                      # 데이터셋에서 체크포인트 검색을 활성화하여 웹UI로 연결하기\n",
    "\n",
    "ui_theme = None                                        # 웹 UI 테마를 설정합니다. 값은 없음(기본값) 또는 '어둡게'일 수 있습니다.\n",
    "\n",
    "insecure_extension_access = False                      # 비밀번호 없이 확장 프로그램을 강제로 활성화합니다.\n",
    "                                                       # 비밀번호를 설정하지 않으면 누구나 임의의 코드를 설치하여 실행할 수 있습니다!\n",
    "                                                       # 대신, 설정 시 자동으로 확장 기능을 활성화하는 gradio_auth를 사용하세요.\n",
    "\n",
    "gradio_queue = False                                   # 그라데이션 대기열 사용; 실험적 옵션; UI 다시 시작 버튼이 깨집니다.\n",
    "\n",
    "install_pip_xformers = False                           # pip를 통해 xformers를 설치합니다. Torch 2.0이 필요하기 때문에 아마 작동하지 않을 것입니다.\n",
    "\n",
    "# ===================================================================================================\n",
    "# 커널이 재시작되더라도 변수에 액세스할 수 있도록 변수를 Jupiter의 임시 저장소에 저장합니다.\n",
    "%store symlink_to_notebooks model_storage_dir repo_storage_dir export_storage_dir activate_xformers link_novelai_anime_vae activate_deepdanbooru activate_medvram disable_pickle_check gradio_port gradio_auth search_paperspace_datasets ui_theme insecure_extension_access pip_cache_dir gradio_queue install_pip_xformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>오류가 표시되면 설정을 확인하세요!</mark>\n",
    "\n",
    "**하단의 [도구 섹션에 있는 블록](#Download-the-latest-version-of-this-notebook-from-Github)을 클릭해 이 노트북을 Github에서 [최신 버전으로](https://github.com/Engineer-of-Stuff/stable-diffusion-paperspace/blob/main/StableDiffusionUI_Voldemort_paperspace.ipynb) 업데이트하는것을 잊지 마세요!**\n",
    "이 버전은 한국어 버전으로 번역만을 지원하며 별도의 지원을 보증하지 않습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## WebUI 저장소 복제\n",
    "\n",
    "\"fatal: destination path already exists and is not an empty directory\"와 같은 오류가 발생하면 `.git` 폴더가 누락된 것입니다. \n",
    "`repo_storage_dir/stable-diffusion-webui`를 삭제하고 다시 설치하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sBbcB4vwj_jm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 모든 셀의 시작 부분에 이 작은 코드 블록이 표시됩니다.\n",
    "# 설정을 정의하는 첫 번째 블록을 실행했는지 확인합니다.\n",
    "try:\n",
    "    %store -r symlink_to_notebooks model_storage_dir repo_storage_dir\n",
    "    test = [symlink_to_notebooks, model_storage_dir, repo_storage_dir]\n",
    "except NameError as e:\n",
    "    print(\"변수에 문제가 있습니다.\")\n",
    "    print(\"첫 번째 블록으로 돌아가서 설정이 올바른지 확인한 다음 셀을 실행하세요.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "    \n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "repo_storage_dir = Path(repo_storage_dir)\n",
    "stable_diffusion_webui_path = repo_storage_dir / 'stable-diffusion-webui'\n",
    "\n",
    "if not (stable_diffusion_webui_path / '.git').exists():    \n",
    "    # stable_diffusion_webui_path가 이미 존재하지만 리포지토리가 다운로드되지 않았을 수 있습니다.\n",
    "    # 수동으로 리포지토리를 초기화하겠습니다.\n",
    "    !mkdir -p \"{stable_diffusion_webui_path}\"\n",
    "    %cd \"{stable_diffusion_webui_path}\"\n",
    "    !git init\n",
    "    !git remote add origin https://github.com/AUTOMATIC1111/stable-diffusion-webui\n",
    "    !git fetch\n",
    "    !git checkout -t origin/master -f\n",
    "    # !git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui \"{stable_diffusion_webui_path}\"\n",
    "else:\n",
    "    print('stable-diffusion-webui가 이미 다운로드 됨, 업데이트중...')\n",
    "    !cd \"{stable_diffusion_webui_path}\" && git pull # %를 사용하지 않으므로 메인 프로세스를 방해하지 않습니다.\n",
    "\n",
    "!mkdir -p \"{repo_storage_dir / 'stable-diffusion-webui' / 'outputs'}\"\n",
    "!mkdir -p \"{repo_storage_dir / 'stable-diffusion-webui' / 'log'}\"\n",
    "\n",
    "symlinks = [\n",
    "    (repo_storage_dir / 'stable-diffusion-webui', Path('/notebooks/stable-diffusion-webui')),\n",
    "    (repo_storage_dir / 'stable-diffusion-webui' / 'outputs', Path('/notebooks/outputs')),\n",
    "    (repo_storage_dir / 'stable-diffusion-webui' / 'log', repo_storage_dir / 'stable-diffusion-webui' / 'outputs' / 'log'),\n",
    "    (Path('/storage'), Path('/notebooks/storage')),\n",
    "    (Path(model_storage_dir), Path('/notebooks/models')),\n",
    "           ]\n",
    "\n",
    "if symlink_to_notebooks and repo_storage_dir != '/notebooks':\n",
    "    print('\\n심볼릭 링크 생성...')\n",
    "    for src, dest in symlinks:\n",
    "        # `/notebooks/stable-diffusion-webui`가 깨진 심볼릭 링크인 경우 이를 제거합니다.\n",
    "        # WebUI가 이전에 비영구 디렉터리에 설치되었을 수 있습니다.\n",
    "        if dest.is_symlink() and not dest.exists(): # .exists()는 심볼릭 링크의 유효성을 검사합니다.\n",
    "            print('심볼릭 링크가 끊어져 제거되었습니다:', dest)\n",
    "            dest.unlink()\n",
    "        if not dest.exists():\n",
    "            os.symlink(src, dest)\n",
    "        print(os.path.realpath(dest), '->', dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Python 3.10\n",
    "\n",
    "Python 3.10은 웹UI를 실행하는 데 권장되는 Python 버전입니다. Paperspace는 컨테이너에 Python 3.9를 사용하므로 사용자 정의 컨테이너를 사용해야 합니다. \n",
    "다행히도 여러분이 사용할 수 있는 컨테이너를 만들었습니다.\n",
    "\n",
    "먼저, 다음 안내에 따라 현재 노트북을 삭제하고 새 노트북을 만드세요: https://docs.paperspace.com/gradient/notebooks/runtimes/#how-to-specify-a-custom-container\n",
    "\n",
    "이 컨테이너 이미지를 사용해야 합니다: `cyberes/gradient-base-py3.10`\n",
    "\n",
    "아래 블록을 사용하여 Python 버전을 테스트할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "version = sys.version.split(' ')[0]\n",
    "v_parts = version.split('.')\n",
    "if int(v_parts[1]) < 10:\n",
    "    print(f'사용 중인 Python 버전이 3.10 미만입니다. -> {version}')\n",
    "else:\n",
    "    print('Python 버전이 양호합니다:', version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특수 Python 3.10 컨테이너 *cyberes/gradient-base-py3.10:latest*를 사용하는 경우 pip를 통해 xformers를 설치하거나 직접 빌드해야 합니다.\n",
    "\n",
    "먼저 위의 설정 블록에서 `install_pip_xformers = True`를 설정하여 pip를 통해 설치해 보세요. 실패하거나 문제가 발생하면 도구 섹션의 블록을 사용하여 머신에 맞는 xformers를 빌드하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C68TUpkq0nj_",
    "tags": []
   },
   "source": [
    "## 요구 사항 설치 및 리포지토리 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SaAJk33ppFw1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    %store -r symlink_to_notebooks model_storage_dir repo_storage_dir activate_xformers activate_deepdanbooru pip_cache_dir install_pip_xformers \n",
    "    test = [symlink_to_notebooks, model_storage_dir, repo_storage_dir, activate_xformers, activate_deepdanbooru, pip_cache_dir, install_pip_xformers]\n",
    "except NameError as e:\n",
    "    print(\"변수에 문제가 있습니다.\")\n",
    "    print(\"첫 번째 블록으로 돌아가서 설정이 올바른지 확인한 다음 셀을 실행하세요.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "%cd \"{Path(repo_storage_dir, 'stable-diffusion-webui')}\"\n",
    "\n",
    "!pip install --upgrade pip\n",
    "!pip install --upgrade wheel setuptools\n",
    "\n",
    "if pip_cache_dir:\n",
    "    !pip install git+https://github.com/pixelb/crudini.git\n",
    "    !mkdir -p \"{pip_cache_dir}\"\n",
    "    !python3 -m crudini --set /etc/pip.conf global cache-dir \"{pip_cache_dir}\"\n",
    "    !echo \"Set pip cache directory: $(pip cache dir)\"\n",
    "\n",
    "# WebUI가 필요한 버전을 설치할 수 있도록 PyTorch 및 기타 라이브러리를 제거합니다.\n",
    "!pip uninstall -y torch torchvision torchaudio protobuf\n",
    "\n",
    "# 자동으로 설치 스크립트를 실행하지만 WebUI를 실행하지 않는 launch.py를 가져옵니다.\n",
    "import launch\n",
    "launch.prepare_environment()\n",
    "\n",
    "# 이 노트북에 필요한 항목 설치\n",
    "!pip install requests gdown bs4 markdownify\n",
    "\n",
    "# 지금 Installer가 DeepDanbooru를 설치하지 않고 있으므로 수동으로 설치하겠습니다.\n",
    "if activate_deepdanbooru:\n",
    "    # https://github.com/KichangKim/DeepDanbooru/releases\n",
    "    !pip install \"git+https://github.com/KichangKim/DeepDanbooru.git@v3-20211112-sgd-e28#egg=deepdanbooru[tensorflow]\" # $(curl --silent \"https://api.github.com/KichangKim/DeepDanbooru/releases/latest\" | grep '\"tag_name\":' | sed -E 's/.*\"([^\"]+)\".*/\\1/')#egg=deepdanbooru[tensorflow]\" # tensorflow==2.10.0 tensorflow-io==0.27.0 flatbuffers==1.12\n",
    "\n",
    "# WebUI 인스톨러가 나중에 올바른 버전의 PyTorch를 설치할 수 있도록 xformers를 먼저 설치해야 합니다.\n",
    "if activate_xformers:\n",
    "    if install_pip_xformers:\n",
    "        print('Installing xformers through pip...')\n",
    "        !pip install --no-dependencies xformers\n",
    "    else:\n",
    "        import subprocess\n",
    "        from glob import glob\n",
    "        def download_release(url, binary_name='xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl'):\n",
    "            tmp_dir = subprocess.check_output(['mktemp', '-d']).decode('ascii').strip('\\n')\n",
    "            !wget \"{url}\" -O \"{tmp_dir}/{binary_name}\"\n",
    "            return os.path.join(tmp_dir, binary_name)\n",
    "\n",
    "        xformers_whl = None\n",
    "        found_xformers_whls = glob('/notebooks/xformers-*')\n",
    "        if len(found_xformers_whls) == 1:\n",
    "            print('Installing xformers using your pre-built wheel...')\n",
    "            xformers_whl = found_xformers_whls[0]\n",
    "            delete_whl = False\n",
    "        elif len(found_xformers_whls) > 1:\n",
    "            print('Found more than one Xformers wheel in /notebooks so not doing anything!')\n",
    "        else:\n",
    "            print('Installing xformers from wheels on Github...')\n",
    "            delete_whl = True\n",
    "            # pip packages 설치\n",
    "            # !pip uninstall -y torch  torchvision torchaudio # 기존 pytorch 삭제\n",
    "            # !pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113 # cuda 11.3을 위한 pytorch 설치\n",
    "            s = subprocess.getoutput('nvidia-smi')\n",
    "            if 'A4000' in s:\n",
    "                xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/raw/main/a4000/xformers-0.0.18%2Bda27862.d20230413-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'A5000' in s:\n",
    "                xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/A5000-Nov-1-2022/a5000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'A6000' in s:\n",
    "                xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/A6000-Nov-1-2022/a6000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'P5000' in s:\n",
    "                xformers_whl = download_release('https://raw.githubusercontent.com/Cyberes/xformers-compiled/main/p5000/xformers-0.0.16%2B6f3c20f.d20230127-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'RTX 4000' in s:\n",
    "                xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/RTX-4000-Nov-1-2022/rtx4000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'RTX 5000' in s:\n",
    "                xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/RTX-5000-Nov-1-2022/rtx5000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'A100' in s:\n",
    "                xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/A100-Nov-1-2022/a100-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'M4000' in s:\n",
    "                print('xformers for M4000 hasn\\'t been built yet.')\n",
    "                # xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/A100-Nov-1-2022/a100-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            else:\n",
    "                print('GPU가 xformers 바이너리와 일치하지 않아 획일적인 바이너리가 설치되었습니다. 문제가 있는 경우 아래 도구 블록을 사용하여 xformers를 빌드하세요.')\n",
    "                xformers_whl = download_release('https://raw.githubusercontent.com/Cyberes/xformers-compiled/main/various/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl')\n",
    "        if xformers_whl:\n",
    "            !pip uninstall -y xformers\n",
    "            # xformers는 이미 설치되어 있어야 하므로 종속성을 설치하지 않고 설치하겠습니다.\n",
    "            # 문제가 있는 경우 --no-dependencies를 --force-reinstall으로 대체하세요.\n",
    "            !pip install --no-dependencies \"{xformers_whl}\"\n",
    "            if delete_whl:\n",
    "                !rm -rf \"{xformers_whl}\"\n",
    "# 중요한 디렉터리가 존재하는지 확인\n",
    "!mkdir -p \"{model_storage_dir}/hypernetworks\"\n",
    "!mkdir -p \"{model_storage_dir}/vae\"\n",
    "!mkdir -p \"{repo_storage_dir}/stable-diffusion-webui/models/hypernetworks\"\n",
    "!mkdir -p \"{repo_storage_dir}/stable-diffusion-webui/models/VAE\"\n",
    "!mkdir -p \"{repo_storage_dir}/stable-diffusion-webui/models/Lora\"\n",
    "!mkdir -p \"{repo_storage_dir}/stable-diffusion-webui/log/images\"\n",
    "\n",
    "!echo -e \"\\n===================================\\n완료! 이 메시지가 표시되면 프로세스가 성공적으로 종료된 것입니다.\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0EINk5M0s-w",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 모델 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미 모델을 다운로드한 경우에는 이 단계를 반복할 필요가 없습니다.\n",
    "\n",
    "<br>\n",
    "\n",
    "### 파일 크기 및 스토리지 면책 조항\n",
    "\n",
    "저장 용량에 문제가 있는 경우 몇 가지 제안 사항이 있습니다.\n",
    "1. 컴퓨터를 시작할 때마다 `/tmp/`에 모든 파일을 다운로드합니다.\n",
    "2. 계정에 결제 방법을 추가합니다. 스토리지 초과분은 \\$0.29/GB로 청구되며, 매월 청구는 매월 1일 자정에 이루어집니다. 결제 방법을 등록해 두면 Paperspace에서 더 많은 용량을 사용할 수 있으며, 시간을 잘 맞추면 실제로 요금이 청구되지 않습니다.\n",
    "3. Growth 계정으로 업그레이드합니다. 50GB가 제공되며 더 긴 런타임과 더 강력한 무료 GPU를 이용할 수 있습니다.\n",
    "\n",
    "### 토렌트 지침\n",
    "\n",
    "다운로드하는 동안 Aria2에 몇 가지 오류/경고가 표시될 수 있습니다. 결국 \"다운로드 완료\"라고 표시되면 모든 것이 정상적으로 작동한다는 의미이므로 괜찮습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토렌트 마그넷 링크, 웹 링크, 구글 드라이브, 허깅페이스 또는 CivitAI에서 모델을 다운로드할 수 있는 도구가 있습니다.\n",
    "\n",
    "웹사이트가 업데이트되어 이 다운로드가 구식이 될 수 있습니다. 문제가 발생하면 이 노트북의 리포지토리에서 [문제 제기](https://github.com/ghkimwoo/stable-diffusion-paperspace-korean/issues/new)를 해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir\n",
    "    test = [model_storage_dir, repo_storage_dir]\n",
    "except NameError as e:\n",
    "    print(\"변수에 문제가 있습니다.\")\n",
    "    print(\"첫 번째 블록으로 돌아가서 설정이 올바른지 확인한 다음 셀을 실행하세요.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "model_uri = input('다운로드할 모델의 URI 입력: ')\n",
    "import re\n",
    "import requests\n",
    "import gdown\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from markdownify import markdownify\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36'\n",
    "\n",
    "def is_url(url_str):\n",
    "    return re.search(r'https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,}', url_str)\n",
    "\n",
    "def dl_web_file(web_dl_file, filename=None):\n",
    "    web_dl_file = is_url(web_dl_file)[0] # clean the URL string\n",
    "    !if [ $(dpkg-query -W -f='${Status}' aria2 2>/dev/null | grep -c \"ok installed\") = 0 ]; then sudo apt update && sudo apt install -y aria2; fi\n",
    "    if filename:\n",
    "        filename_cmd = f'--out=\"{filename}\"'\n",
    "    else:\n",
    "        filename_cmd = ''\n",
    "    # We're going to use aria2 to split the download into threads which will allow us to download\n",
    "    # the file very fast even if the site serves the file slow.\n",
    "    !cd \"{model_storage_dir}\" && aria2c --file-allocation=none -c -x 16 -s 16 --summary-interval=0 --console-log-level=warn --continue --user-agent \"{user_agent}\" {filename_cmd} \"{web_dl_file}\" \n",
    "\n",
    "magnet_match = re.search(r'magnet:\\?xt=urn:btih:[\\-_A-Za-z0-9&=%.]*', model_uri)\n",
    "civitai_match = re.search(r'^https?:\\/\\/(?:www\\.|(?!www))civitai\\.com\\/models\\/\\d*\\/.*?$', model_uri)\n",
    "web_match = is_url(model_uri)\n",
    "\n",
    "if magnet_match:\n",
    "    !if [ $(dpkg-query -W -f='${Status}' aria2 2>/dev/null | grep -c \"ok installed\") = 0 ]; then sudo apt update && sudo apt install -y aria2; fi\n",
    "    %cd \"{model_storage_dir}\"\n",
    "    bash_var = magnet_match[0]\n",
    "    !aria2c --seed-time=0 --max-overall-upload-limit=1K --bt-max-peers=120 --summary-interval=0 --console-log-level=warn --file-allocation=none \"{bash_var}\"\n",
    "    # clean exit here\n",
    "elif 'https://huggingface.co/' in model_uri:\n",
    "    from urllib.parse import urlparse\n",
    "    filename = os.path.basename(urlparse(model_uri.replace('/blob/', '/resolve/')).path)\n",
    "    response = requests.head(model_uri, allow_redirects=True, headers={'User-Agent': user_agent})\n",
    "    if 'octet-stream' not in response.headers['content-type']:\n",
    "        response = requests.head(model_uri.replace('/blob/', '/resolve/'), allow_redirects=True, headers={'User-Agent': user_agent})\n",
    "        if 'octet-stream' not in response.headers['content-type']:\n",
    "            print(f'잘못된 콘텐츠 유형: {response.headers[\"content-type\"].split(\";\")[0]}')\n",
    "            # clean exit here\n",
    "        else:\n",
    "            dl_web_file(model_uri.replace('/blob/', '/resolve/'), filename)\n",
    "            # clean exit here\n",
    "    else:\n",
    "        dl_web_file(model_uri, filename)\n",
    "        # clean exit here\n",
    "elif 'https://drive.google.com' in model_uri:\n",
    "    gdrive_file_id, _ = gdown.parse_url.parse_url(model_uri)\n",
    "    %cd \"{model_storage_dir}\"\n",
    "    gdown.download(f\"https://drive.google.com/uc?id={gdrive_file_id}&confirm=t\")\n",
    "    # clean exit here\n",
    "elif civitai_match:\n",
    "    if not is_url(civitai_match[0]):\n",
    "        print('URL이 알려진 civitai.com 패턴과 일치하지 않습니다.')\n",
    "        # clean exit here\n",
    "    else:\n",
    "        soup = BeautifulSoup(requests.get(model_uri, headers={'User-Agent': user_agent}).text, features=\"html.parser\")\n",
    "        data = json.loads(soup.find('script', {'id': '__NEXT_DATA__'}).text)\n",
    "        model_data = data[\"props\"][\"pageProps\"][\"trpcState\"][\"json\"][\"queries\"][0][\"state\"][\"data\"]\n",
    "        latest_model = model_data['modelVersions'][0]\n",
    "        latest_model_url = f\"https://civitai.com/api/download/models/{latest_model['id']}\"\n",
    "        print('모델 다운로드중:', model_data['name'])\n",
    "        \n",
    "        # Download the description to a markdown file next to the checkpoint\n",
    "        desc = markdownify(model_data['description'])\n",
    "        req = urllib.request.Request(latest_model_url, data=None, headers={'User-Agent': user_agent})\n",
    "        content_disp = urllib.request.urlopen(req).getheader('Content-Disposition')\n",
    "        if content_disp:\n",
    "            filename = Path(re.match(r'attachment; filename=\"(.*?)\"', content_disp)[1]).stem\n",
    "            with open(Path(model_storage_dir, f'{filename}.md'), 'w') as file:\n",
    "                file.write(f\"# {model_data['name']}\\n\")\n",
    "                file.write(f'Original CivitAI URL: {model_uri}\\n\\n<br>\\n\\n')\n",
    "                file.write(desc)\n",
    "        else:\n",
    "            print('Markdown 파일의 체크포인트 파일명을 가져오지 못했습니다.')\n",
    "        dl_web_file(latest_model_url)\n",
    "        # clean exit here\n",
    "elif web_match:\n",
    "    # Always do the web match last\n",
    "    with requests.get(web_match[0], allow_redirects=True, stream=True, headers={'User-Agent': user_agent}) as r:\n",
    "        # Uing GET since some servers respond differently to HEAD.\n",
    "        # Using `with` so we can close the connection and not download the entire file.\n",
    "        response = r\n",
    "        r.close()\n",
    "    if response.headers.get('content-type') or response.headers.get('content-disposition'):\n",
    "        if 'octet-stream' in response.headers.get('content-type', '') or 'attachment' in response.headers.get('content-disposition', ''):\n",
    "            dl_web_file(model_uri)\n",
    "            # clean exit here\n",
    "        else:\n",
    "            print('필수 HTTP 헤더가 올바르지 않습니다. 이 중 하나가 정확해야 합니다:', end='\\n\\n')\n",
    "            print('Content-type:', response.headers['content-type'].split(\";\")[0] if response.headers.get('content-type') else 'None')\n",
    "            print('\"application/octet-stream\"이어야 합니다.', end='\\n\\n')\n",
    "            print('Content-Disposition:', response.headers['content-disposition'] if response.headers.get('content-disposition') else 'None')\n",
    "            print('\"첨부 파일\"로 시작해야 합니다.')\n",
    "            # clean exit here\n",
    "    else:\n",
    "        print('필수 HTTP 헤더가 누락되었습니다. 최소한 이 중 하나가 필요합니다:', end='\\n\\n')\n",
    "        print('Content-Type:', response.headers['content-type'].split(\";\")[0] if response.headers.get('content-type') else 'None')\n",
    "        print('\"application/octet-stream\"이어야 합니다.', end='\\n\\n')\n",
    "        print('Content-Disposition:', response.headers['content-disposition'] if response.headers.get('content-disposition') else 'None')\n",
    "        print('\"첨부 파일\"로 시작해야 합니다.')\n",
    "else:\n",
    "    print('URI를 구문 분석하지 못했습니다.')\n",
    "    # clean exit here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 커널 정리 및 재시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir pip_cache_dir\n",
    "    test = [model_storage_dir, repo_storage_dir, pip_cache_dir]\n",
    "except NameError as e:\n",
    "    print(\"변수에 문제가 있습니다.\")\n",
    "    print(\"첫 번째 블록으로 돌아가서 설정이 올바른지 확인한 다음 셀을 실행하세요.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "# Get some storage back\n",
    "if not pip_cache_dir:\n",
    "    !pip cache purge\n",
    "    !echo \"Purged pip cache\"\n",
    "!cd \"{model_storage_dir}\" && rm *.aria2\n",
    "!apt remove --purge -y aria2 p7zip-full\n",
    "!apt autoremove --purge -y\n",
    "!apt clean\n",
    "\n",
    "# Restart the kernel\n",
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 디렉터리 링크\n",
    "\n",
    "심볼릭 링크를 생성합니다. 파일은 모델 저장 디렉터리에 저장되며 웹UI에서 파일이 있을 것으로 예상되는 위치에 연결됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir link_novelai_anime_vae search_paperspace_datasets\n",
    "    test = [model_storage_dir, repo_storage_dir, link_novelai_anime_vae, search_paperspace_datasets]\n",
    "except NameError as e:\n",
    "    print(\"변수에 문제가 있습니다.\")\n",
    "    print(\"첫 번째 블록으로 돌아가서 설정이 올바른지 확인한 다음 셀을 실행하세요.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "model_storage_dir = Path(model_storage_dir)\n",
    "\n",
    "if not model_storage_dir.exists():\n",
    "    print('모델 저장 디렉터리가 존재하지 않습니다:', model_storage_dir)\n",
    "    sys.exit(1)\n",
    "\n",
    "webui_root_model_path = Path(repo_storage_dir, 'stable-diffusion-webui/models')\n",
    "webui_sd_model_path = Path(webui_root_model_path, 'Stable-diffusion')\n",
    "webui_hypernetwork_path = Path(webui_root_model_path, 'hypernetworks')\n",
    "webui_vae_path = Path(webui_root_model_path, 'VAE')\n",
    "webui_lora_model_path = Path(webui_root_model_path, 'Lora')\n",
    "\n",
    "def delete_broken_symlinks(dir):\n",
    "    deleted = False\n",
    "    dir = Path(dir)\n",
    "    for file in dir.iterdir():\n",
    "        if file.is_symlink() and not file.exists():\n",
    "            print('심볼 링크가 끊어짐, 제거중:', file)\n",
    "            file.unlink()\n",
    "            deleted = True\n",
    "    if deleted:\n",
    "        print('')\n",
    "\n",
    "def create_symlink(source, dest):\n",
    "    if os.path.isdir(dest):\n",
    "        dest = Path(dest, os.path.basename(source))\n",
    "    if not dest.exists():\n",
    "        os.symlink(source, dest)\n",
    "    print(source, '->', Path(dest).absolute())\n",
    "\n",
    "# 깨진 심볼릭 링크가 있는지 확인하고 제거합니다.\n",
    "print('깨진 심볼릭 링크 제거 중...')\n",
    "delete_broken_symlinks(webui_sd_model_path)\n",
    "delete_broken_symlinks(webui_hypernetwork_path)\n",
    "delete_broken_symlinks(webui_vae_path)\n",
    "delete_broken_symlinks(webui_lora_model_path)\n",
    "\n",
    "def link_ckpts(source_path):\n",
    "    #.ckpt 및 .safetensor/.st 파일 연결(재귀적)\n",
    "    print('\\n.ckpt 및 .safetensor/.safetensors/.st 파일에 연결하기', source_path)\n",
    "    source_path = Path(source_path)\n",
    "    for file in [p for p in source_path.rglob('*') if p.suffix in ['.ckpt', '.safetensor', '.safetensors', '.st']]:\n",
    "        if Path(file).parent.parts[-1] not in ['hypernetworks', 'vae'] :\n",
    "            if not (webui_sd_model_path / file.name):\n",
    "                print('새 모델:', file.name)\n",
    "            create_symlink(file, webui_sd_model_path)\n",
    "    # 구성 yaml 파일 연결\n",
    "    print('\\n구성 .yaml 파일 연결', source_path)\n",
    "    for file in model_storage_dir.glob('*.yaml'):\n",
    "        create_symlink(file, webui_sd_model_path)\n",
    "\n",
    "\n",
    "link_ckpts(model_storage_dir)\n",
    "\n",
    "# 하이퍼네트워크 연결\n",
    "print('\\nhypernetwork 연결 중...')\n",
    "hypernetwork_source_path = Path(model_storage_dir, 'hypernetworks')\n",
    "if hypernetwork_source_path.is_dir():\n",
    "    for file in hypernetwork_source_path.iterdir():\n",
    "        create_symlink(hypernetwork_source_path / file, webui_hypernetwork_path)\n",
    "else:\n",
    "    print('하이퍼네트워크 저장소 위치를 찾을 수 없습니다:', hypernetwork_source_path)\n",
    "\n",
    "# VAE 연결\n",
    "print('\\nVAE 연결 중...')\n",
    "vae_source_path = Path(model_storage_dir, 'vae')\n",
    "if vae_source_path.is_dir():\n",
    "    for file in vae_source_path.iterdir():\n",
    "        create_symlink(vae_source_path / file, webui_vae_path)\n",
    "else:\n",
    "    print('VAE 저장 위치를 찾을 수 없습니다:', vae_source_path)\n",
    "\n",
    "# 로라 링크\n",
    "print('\\n로라 연결 중...')\n",
    "lora_source_path = Path(model_storage_dir, 'Lora')\n",
    "if lora_source_path.is_dir():\n",
    "    for file in lora_source_path.iterdir():\n",
    "        create_symlink(lora_source_path / file, webui_lora_model_path)\n",
    "else:\n",
    "    print('Lora storage directory not found:', lora_source_path)\n",
    "\n",
    "# 각 NovelAI 모델에 대한 NovelAI 파일 연결하기\n",
    "print('\\n각 NovelAI 모델에 대한 NovelAI 파일 연결...')\n",
    "for model in model_storage_dir.glob('novelai-*.ckpt'):\n",
    "    yaml = model.stem + '.yaml'\n",
    "    if os.path.exists(yaml):\n",
    "        print('새로운 NovelAI 모델 구성:', yaml)\n",
    "        create_symlink(yaml, webui_sd_model_path)\n",
    "\n",
    "if link_novelai_anime_vae:\n",
    "    print('\\nNovelAI 애니메이션 VAE 연동 중...')\n",
    "    for model in model_storage_dir.glob('novelai-*.ckpt'):\n",
    "        if (model_storage_dir / 'hypernetworks' / 'animevae.pt').is_file():\n",
    "            vae = model.stem + '.vae.pt'\n",
    "            if not os.path.exists(webui_vae_path):\n",
    "                print(f'Linking NovelAI {vae} and {model}')\n",
    "            create_symlink(model_storage_dir / 'hypernetworks' / 'animevae.pt', webui_vae_path)\n",
    "        else:\n",
    "            print(f'{model_storage_dir}/hypernetworks/animevae.pt를 찾을 수 없습니다!')\n",
    "\n",
    "if search_paperspace_datasets:\n",
    "    if Path('/datasets').is_dir():\n",
    "        link_ckpts('/datasets')\n",
    "    else:\n",
    "        print('\\n탑재된 데이터 세트가 없습니다!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xt8lbdmC04ox"
   },
   "source": [
    "# WebUI 시작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "이 블록을 실행하여 WebUI를 시작합니다. WebUI인 nnn.gradio.app에 대한 링크가 표시됩니다. 링크를 따라갑니다.\n",
    "\n",
    "시작 인수의 코드를 보려면 [shared.py](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/master/modules/shared.py#L22)를 참조하세요. 인자가 정확히 무엇을 하는지에 대한 좋은 정보가 많이 있습니다. 프로그래머가 아니라면 [이 위키](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Command-Line-Arguments-and-Settings)를 참조하세요.\n",
    "\n",
    "#### 문제 해결\n",
    "- 문제가 발생하면 커널을 다시 시작해 보세요.\n",
    "- `EOFError: Ran out of input`는 아마도 저장 공간이 부족하여 모델 `.ckpt` 파일을 완전히 다운로드하지 못했음을 의미합니다. 파일을 정리해 보세요. 아래 도구 섹션에 몇 가지 유용한 스크립트가 있습니다.\n",
    "- `The file may be malicious, so the program is not going to read it` 는 프로그램이 모델 파일에서 예기치 않은 데이터(전문 용어는 'pickle')를 발견했다는 의미입니다. 모델 병합이 이 문제를 일으킬 수 있습니다. 이 기능은 설정 블록에서 `disable_pickle_check`를 True로 설정하여 비활성화할 수 있습니다.\n",
    "- 아래 도구 섹션의 블록을 사용해 노트북을 업데이트해 보세요.\n",
    "- 그래도 문제가 계속 발생하면 `stable-diffusion-webui`를 삭제하고 다시 설치하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-xAdMA5wxXd",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir activate_xformers activate_deepdanbooru activate_medvram disable_pickle_check gradio_port gradio_auth ui_theme insecure_extension_access gradio_queue\n",
    "    test = [model_storage_dir, repo_storage_dir, activate_xformers, activate_deepdanbooru, activate_medvram, disable_pickle_check, gradio_port, gradio_auth, ui_theme, insecure_extension_access, gradio_queue]\n",
    "except NameError as e:\n",
    "    print(\"변수에 문제가 있습니다.\")\n",
    "    print(\"첫 번째 블록으로 돌아가서 설정이 올바른지 확인한 다음 셀을 실행하세요.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "from pathlib import Path\n",
    "%cd \"{Path(repo_storage_dir, 'stable-diffusion-webui')}\"\n",
    "\n",
    "# 첫 번째 블록에 정의된 대로 원하는 옵션을 설정하는 코드를 작성합니다.\n",
    "x_arg = '--xformers' if activate_xformers else ''\n",
    "dd_arg = '--deepdanbooru' if activate_deepdanbooru else ''\n",
    "mvram_arg = '--medvram' if activate_medvram else ''\n",
    "pickled = '--disable-safe-unpickle' if disable_pickle_check else ''\n",
    "port = f'--port {gradio_port}' if gradio_port else '--share'\n",
    "auth = f'--gradio-auth {gradio_auth} --enable-insecure-extension-access' if gradio_auth else ''\n",
    "theme = f'--theme {ui_theme}' if ui_theme else ''\n",
    "insecure_extension_access = '--enable-insecure-extension-access' if insecure_extension_access else ''\n",
    "queue = '--gradio-queue' if gradio_queue else ''\n",
    "\n",
    "# Launch args go below:\n",
    "!python webui.py {x_arg} {dd_arg} {mvram_arg} {pickled} {port} {auth} {theme} {queue}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 내보내기 생성\n",
    "\n",
    "이 블록은 출력의 이름을 바꾸고 7zip 최대 압축으로 압축합니다. `/notebooks/stable-diffusion-webui/`에 `log/`와 `outputs/`이 있을 것으로 예상합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir export_storage_dir\n",
    "    test = [model_storage_dir, repo_storage_dir, export_storage_dir]\n",
    "except NameError as e:\n",
    "    print(\"변수에 문제가 있습니다.\")\n",
    "    print(\"첫 번째 블록으로 돌아가서 설정이 올바른지 확인한 다음 셀을 실행하세요.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "repo_storage_dir = Path(repo_storage_dir)\n",
    "export_storage_dir = Path(export_storage_dir)\n",
    "export_storage_dir.mkdir(exist_ok=True)\n",
    "\n",
    "!if [ $(dpkg-query -W -f='${Status}' p7zip-full 2>/dev/null | grep -c \"ok installed\") = 0 ]; then sudo apt update && sudo apt install -y p7zip-full; fi # 7z가 아직 설치되어 있지 않다면 설치합니다.\n",
    "from datetime import datetime\n",
    "datetime_str = datetime.now().strftime('%m-%d-%Y_%H-%M-%S')\n",
    "%cd \"{export_storage_dir}\"\n",
    "!mkdir -p \"{datetime_str}/log\"\n",
    "!cd \"{repo_storage_dir / 'stable-diffusion-webui' / 'log'}\" && mv * \"{export_storage_dir / datetime_str / 'log'}\"\n",
    "!cd \"{repo_storage_dir / 'stable-diffusion-webui' / 'outputs'}\" && mv * \"{export_storage_dir / datetime_str}\"\n",
    "s = subprocess.run(f'find \"{Path(export_storage_dir, datetime_str)}\" -type d -name .ipynb_checkpoints -exec rm -rv {{}} +', shell=True)\n",
    "print('폴더 압축:', export_storage_dir / datetime_str)\n",
    "!7z a -t7z -m0=lzma2 -mx=9 -mfb=64 -md=32m -ms=on \"{datetime_str}.7z\" \"{export_storage_dir / datetime_str}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 오래된 출력 폴더 삭제\n",
    "\n",
    "이 블록은 방금 압축한 폴더를 삭제합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf \"{export_storage_dir / datetime_str}\"\n",
    "# !echo \"Deleted {export_storage_dir / datetime_str}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 도구"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Github에서 이 노트북 업데이트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 파일을 실행하고 페이지를 새로고침합니다(F5 키를 누릅니다). 아무것도 저장하지 않으면 다운로드한 파일을 덮어쓰게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv /notebooks/StableDiffusionUI_Voldemort_paperspace.ipynb /notebooks/StableDiffusionUI_Voldemort_paperspace.ipynb.backup # 기존 노트북을 백업에 저장\n",
    "# !wget https://raw.githubusercontent.com/ghkimwoo/stable-diffusion-paperspace-korean/master/StableDiffusionUI_Voldemort_paperspace.ipynb -O /notebooks/StableDiffusionUI_Voldemort_paperspace.ipynb\n",
    "!wget https://raw.githubusercontent.com/Engineer-of-Stuff/stable-diffusion-paperspace/master/StableDiffusionUI_Voldemort_paperspace.ipynb -O /notebooks/StableDiffusionUI_Voldemort_paperspace.ipynb\n",
    "!echo \"다운로드 완료! 이제 페이지를 새로고침합니다(F5 키를 누릅니다). 아무것도 저장하지 않으면 다운로드한 파일을 덮어쓰게 됩니다.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 자동 모델 다운로더"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토렌트 마그넷 링크, 웹 링크, 구글 드라이브, 허깅페이스 또는 CivitAI에서 모델을 다운로드할 수 있는 도구가 있습니다.\n",
    "\n",
    "웹사이트가 업데이트되어 이 다운로드가 구식이 될 수 있습니다. 문제가 발생하면 이 노트북의 리포지토리에서 [문제 제기](https://github.com/ghkimwoo/stable-diffusion-paperspace-korean/issues/new)를 해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir\n",
    "    test = [model_storage_dir, repo_storage_dir]\n",
    "except NameError as e:\n",
    "    print(\"변수에 문제가 있습니다.\")\n",
    "    print(\"첫 번째 블록으로 돌아가서 설정이 올바른지 확인한 다음 셀을 실행하세요.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "model_uri = input('다운로드할 모델의 URI 입력: ')\n",
    "import re\n",
    "import requests\n",
    "import gdown\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from markdownify import markdownify\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36'\n",
    "\n",
    "def is_url(url_str):\n",
    "    return re.search(r'https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,}', url_str)\n",
    "\n",
    "def dl_web_file(web_dl_file, filename=None):\n",
    "    web_dl_file = is_url(web_dl_file)[0] # clean the URL string\n",
    "    !if [ $(dpkg-query -W -f='${Status}' aria2 2>/dev/null | grep -c \"ok installed\") = 0 ]; then sudo apt update && sudo apt install -y aria2; fi\n",
    "    if filename:\n",
    "        filename_cmd = f'--out=\"{filename}\"'\n",
    "    else:\n",
    "        filename_cmd = ''\n",
    "    # We're going to use aria2 to split the download into threads which will allow us to download\n",
    "    # the file very fast even if the site serves the file slow.\n",
    "    !cd \"{model_storage_dir}\" && aria2c --file-allocation=none -c -x 16 -s 16 --summary-interval=0 --console-log-level=warn --continue --user-agent \"{user_agent}\" {filename_cmd} \"{web_dl_file}\" \n",
    "\n",
    "magnet_match = re.search(r'magnet:\\?xt=urn:btih:[\\-_A-Za-z0-9&=%.]*', model_uri)\n",
    "civitai_match = re.search(r'^https?:\\/\\/(?:www\\.|(?!www))civitai\\.com\\/models\\/\\d*\\/.*?$', model_uri)\n",
    "web_match = is_url(model_uri)\n",
    "\n",
    "if magnet_match:\n",
    "    !if [ $(dpkg-query -W -f='${Status}' aria2 2>/dev/null | grep -c \"ok installed\") = 0 ]; then sudo apt update && sudo apt install -y aria2; fi\n",
    "    %cd \"{model_storage_dir}\"\n",
    "    bash_var = magnet_match[0]\n",
    "    !aria2c --seed-time=0 --max-overall-upload-limit=1K --bt-max-peers=120 --summary-interval=0 --console-log-level=warn --file-allocation=none \"{bash_var}\"\n",
    "    # clean exit here\n",
    "elif 'https://huggingface.co/' in model_uri:\n",
    "    from urllib.parse import urlparse\n",
    "    filename = os.path.basename(urlparse(model_uri.replace('/blob/', '/resolve/')).path)\n",
    "    response = requests.head(model_uri, allow_redirects=True, headers={'User-Agent': user_agent})\n",
    "    if 'octet-stream' not in response.headers['content-type']:\n",
    "        response = requests.head(model_uri.replace('/blob/', '/resolve/'), allow_redirects=True, headers={'User-Agent': user_agent})\n",
    "        if 'octet-stream' not in response.headers['content-type']:\n",
    "            print(f'Wrong content-type: {response.headers[\"content-type\"].split(\";\")[0]}')\n",
    "            # clean exit here\n",
    "        else:\n",
    "            dl_web_file(model_uri.replace('/blob/', '/resolve/'), filename)\n",
    "            # clean exit here\n",
    "    else:\n",
    "        dl_web_file(model_uri, filename)\n",
    "        # clean exit here\n",
    "elif 'https://drive.google.com' in model_uri:\n",
    "    gdrive_file_id, _ = gdown.parse_url.parse_url(model_uri)\n",
    "    %cd \"{model_storage_dir}\"\n",
    "    gdown.download(f\"https://drive.google.com/uc?id={gdrive_file_id}&confirm=t\")\n",
    "    # clean exit here\n",
    "elif civitai_match:\n",
    "    if not is_url(civitai_match[0]):\n",
    "        print('URL does not match known civitai.com pattern.')\n",
    "        # clean exit here\n",
    "    else:\n",
    "        soup = BeautifulSoup(requests.get(model_uri, headers={'User-Agent': user_agent}).text, features=\"html.parser\")\n",
    "        data = json.loads(soup.find('script', {'id': '__NEXT_DATA__'}).text)\n",
    "        model_data = data[\"props\"][\"pageProps\"][\"trpcState\"][\"json\"][\"queries\"][0][\"state\"][\"data\"]\n",
    "        latest_model = model_data['modelVersions'][0]\n",
    "        latest_model_url = f\"https://civitai.com/api/download/models/{latest_model['id']}\"\n",
    "        print('Downloading model:', model_data['name'])\n",
    "        \n",
    "        # Download the description to a markdown file next to the checkpoint\n",
    "        desc = markdownify(model_data['description'])\n",
    "        req = urllib.request.Request(latest_model_url, data=None, headers={'User-Agent': user_agent})\n",
    "        content_disp = urllib.request.urlopen(req).getheader('Content-Disposition')\n",
    "        if content_disp:\n",
    "            filename = Path(re.match(r'attachment; filename=\"(.*?)\"', content_disp)[1]).stem\n",
    "            with open(Path(model_storage_dir, f'{filename}.md'), 'w') as file:\n",
    "                file.write(f\"# {model_data['name']}\\n\")\n",
    "                file.write(f'Original CivitAI URL: {model_uri}\\n\\n<br>\\n\\n')\n",
    "                file.write(desc)\n",
    "        else:\n",
    "            print('Failed to get filename of checkpoint for markdown file')\n",
    "        dl_web_file(latest_model_url)\n",
    "        # clean exit here\n",
    "elif web_match:\n",
    "    # Always do the web match last\n",
    "    with requests.get(web_match[0], allow_redirects=True, stream=True, headers={'User-Agent': user_agent}) as r:\n",
    "        # Uing GET since some servers respond differently to HEAD.\n",
    "        # Using `with` so we can close the connection and not download the entire file.\n",
    "        response = r\n",
    "        r.close()\n",
    "    if response.headers.get('content-type') or response.headers.get('content-disposition'):\n",
    "        if 'octet-stream' in response.headers.get('content-type', '') or 'attachment' in response.headers.get('content-disposition', ''):\n",
    "            dl_web_file(model_uri)\n",
    "            # clean exit here\n",
    "        else:\n",
    "            print('Required HTTP headers are incorrect. One of these needs to be correct:', end='\\n\\n')\n",
    "            print('Content-Type:', response.headers['content-type'].split(\";\")[0] if response.headers.get('content-type') else 'None')\n",
    "            print('Must be \"application/octet-stream\"', end='\\n\\n')\n",
    "            print('Content-Disposition:', response.headers['content-disposition'] if response.headers.get('content-disposition') else 'None')\n",
    "            print('Must start with \"attachment;\"')\n",
    "            # clean exit here\n",
    "    else:\n",
    "        print('Required HTTP headers are missing. You need at lease one of these:', end='\\n\\n')\n",
    "        print('Content-Type:', response.headers['content-type'].split(\";\")[0] if response.headers.get('content-type') else 'None')\n",
    "        print('Must be \"application/octet-stream\"', end='\\n\\n')\n",
    "        print('Content-Disposition:', response.headers['content-disposition'] if response.headers.get('content-disposition') else 'None')\n",
    "        print('Must start with \"attachment;\"')\n",
    "else:\n",
    "    print('Could not parse your URI.')\n",
    "    # clean exit here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 사용자 지정 스크립트 컬렉션"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용자 정의 스크립트는 웹UI에 간단한 기능을 추가하는 쉬운 방법입니다. 사용자 정의 스크립트 시스템은 유사한 기능을 제공하는 확장 기능으로 대체되었지만 일부 사람들은 여전히 이러한 스크립트를 사용합니다. 이 블록은 가장 많이 사용되는 몇 가지 스크립트를 설치합니다. 이러한 스크립트 중 일부는 오래되어 작동하지 않을 수 있다는 점에 유의하세요.\n",
    "\n",
    "https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Custom-Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir\n",
    "    test = [model_storage_dir, repo_storage_dir]\n",
    "except NameError as e:\n",
    "    print(\"변수에 문제가 있습니다.\")\n",
    "    print(\"첫 번째 블록으로 돌아가서 설정이 올바른지 확인한 다음 셀을 실행하세요.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "import shutil\n",
    "import requests\n",
    "from pathlib import Path\n",
    "!pip install moviepy==1.0.3\n",
    "!apt update\n",
    "!apt install -y potrace python3-tk\n",
    "\n",
    "def update_repo_if_not_exists(path, repo_clone_url):\n",
    "    if not os.path.exists(path):\n",
    "        !git clone \"{repo_clone_url}\" \"{path}\"\n",
    "    else:\n",
    "        print(f'{repo_clone_url.split(\"/\")[-1]} already downloaded, updating...')\n",
    "        !cd \"{path}\" && git pull # no % so we don't interfere with the main process\n",
    "\n",
    "def download_file_dir(url, output_dir):\n",
    "    # output_dir must have a trailing slash\n",
    "    local_filename = url.split('/')[-1]\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(f'{output_dir}{local_filename}', 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "    return local_filename\n",
    "def do_script_download(scripts_list, domain, path):\n",
    "    for item in scripts_list:\n",
    "        download_file_dir(f'https://{domain}/{item}', path)\n",
    "        print(f'{item.split(\"/\")[-1]} downloaded...')\n",
    "\n",
    "repo_storage_dir = Path(repo_storage_dir)\n",
    "webui_dir = repo_storage_dir / 'stable-diffusion-webui'\n",
    "scripts_dir = webui_dir / 'scripts'\n",
    "        \n",
    "do_script_download([\n",
    "    'GRMrGecko/stable-diffusion-webui-automatic/advanced_matrix/scripts/advanced_prompt_matrix.py',\n",
    "    'dfaker/stable-diffusion-webui-cv2-external-masking-script/main/external_masking.py',\n",
    "    'memes-forever/Stable-diffusion-webui-video/main/videos.py',\n",
    "    'yownas/seed_travel/main/scripts/seed_travel.py',\n",
    "    'Animator-Anon/Animator/main/animation.py',\n",
    "    'Filarius/stable-diffusion-webui/master/scripts/vid2vid.py',\n",
    "    'GeorgLegato/Txt2Vectorgraphics/main/txt2vectorgfx.py',\n",
    "    'yownas/shift-attention/main/scripts/shift_attention.py',\n",
    "    'DiceOwl/StableDiffusionStuff/main/loopback_superimpose.py',\n",
    "    'Engineer-of-Stuff/stable-diffusion-paperspace/main/other/save_steps.py',\n",
    "    'Pfaeff/sd-web-ui-scripts/main/moisaic.py'\n",
    "], 'raw.githubusercontent.com', scripts_dir)\n",
    "\n",
    "do_script_download([\n",
    "    'dfaker/f88aa62e3a14b559fe4e5f6b345db664/raw/791dabfa0ab26399aa2635bcbc1cf6267aa4ffc2/alternate_sampler_noise_schedules.py',\n",
    "    'camenduru/9ec5f8141db9902e375967e93250860f/raw/c1a03eb447548adbef1858c0e69d3567a390d2f4/run_n_times.py'\n",
    "], 'gist.githubusercontent.com', scripts_dir)\n",
    "\n",
    "# Download and set up txt2img2img\n",
    "update_repo_if_not_exists(webui_dir / 'txt2img2img_root', 'https://github.com/ThereforeGames/txt2img2img.git')\n",
    "!cp -r \"{webui_dir}/txt2img2img_root/scripts\" \"{webui_dir}\"\n",
    "!cp -r \"{webui_dir}/txt2img2img_root/txt2img2img\" \"{webui_dir}\"\n",
    "!cp -r \"{webui_dir}/txt2img2img_root/venv\" \"{webui_dir}\"\n",
    "\n",
    "# Download and set up txt2mask\n",
    "update_repo_if_not_exists(webui_dir / 'txt2mask', 'https://github.com/ThereforeGames/txt2mask.git')\n",
    "!echo \"Copying txt2mask...\"\n",
    "!cp -r \"{webui_dir}/txt2mask/repositories/clipseg\" \"{webui_dir}/repositories\"\n",
    "!cp -r \"{webui_dir}/txt2mask/scripts/\" \"{webui_dir}/\"\n",
    "echo \"Done!\n",
    "# Install the dynamic-prompts/wildcard script\n",
    "# !git clone https://github.com/adieyal/sd-dynamic-prompting/ extensions/dynamic-prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 그래픽 카드 정보 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Xformer 빌드 및 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**이 두 블록 중 하나를 실행한 후에는 새 Python 버전을 설치했으므로 위의 설치 관리자 블록을 다시 실행해야 합니다.**\n",
    "\n",
    "먼저 pip를 통해 Xformers를 설치해 보세요:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래도 문제가 계속 발생하면 다음 블록을 사용하여 직접 작성해 보세요. [이전 스크립트](https://github.com/Engineer-of-Stuff/stable-diffusion-paperspace/blob/master/other/build-xformers.sh)를 사용해 볼 수도 있습니다.\n",
    "\n",
    "이 작업은 25분 이상 소요되지만 한 번만 수행하면 됩니다. `/notebooks/`에 Xformers `.whl`을 그대로 두면 노트북의 설치 프로그램에 의해 자동으로 설치됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "apt update && apt install jq\n",
    "pip install ninja\n",
    "\n",
    "TMP=$(mktemp -d)\n",
    "cd \"$TMP\"\n",
    "git clone --no-checkout https://github.com/facebookresearch/xformers.git\n",
    "cd xformers\n",
    "LATEST_TAG=$(git describe --tags `git rev-list --tags --max-count=1`)\n",
    "echo \"Building version: $LATEST_TAG\"\n",
    "\n",
    "XFORMERS_DISABLE_FLASH_ATTN=1 NVCC_FLAGS=\"--use_fast_math -DXFORMERS_MEM_EFF_ATTENTION_DISABLE_BACKWARD\" MAX_JOBS=$(nproc) pip wheel --no-dependencies --wheel-dir=\"$TMP\" \"git+https://github.com/facebookresearch/xformers.git@$LATEST_TAG#egg=xformers\"\n",
    "if [[ $? -eq 0 ]]; then\n",
    "    echo -e \"Finished!\\nMoving .whl to /notebooks/\"\n",
    "    cp \"$TMP\"/xformers-* /notebooks/\n",
    "    echo \"Here is your wheel file:\"\n",
    "    find /notebooks -name xformers-*.whl\n",
    "    echo \"Installing your new Xformers wheel...\"\n",
    "    pip install --force-reinstall --no-dependencies \"$TMP\"/xformers-*\n",
    "fi\n",
    "rm -rf \"$TMP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart the kernel\n",
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 리포지토리 초기화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "때때로 AUTOMATIC1111이 무언가를 고장냅니다. https://github.com/AUTOMATIC1111/stable-diffusion-webui/commits/master 로 이동하여 되돌릴 커밋을 선택합니다.\n",
    "\n",
    "특정 날짜를 찾고 있다면 이렇게 하세요: `git log --since='Sept 17 2022' --until='Sept 18 2022'`\n",
    "\n",
    "**이렇게 해도 출력물이나 파일에 변경한 내용이 삭제되지는 않지만, 만약을 대비해 중요한 자료는 백업해 두는 것이 좋습니다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir\n",
    "    test = [model_storage_dir, repo_storage_dir]\n",
    "except NameError as e:\n",
    "    print(\"There is an issue with your variables.\")\n",
    "    print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "from pathlib import Path\n",
    "%cd \"{Path(repo_storage_dir, 'stable-diffusion-webui')}\"\n",
    "!git reset --hard <commit>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### .ipynb_checkpoint 삭제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주피터는 임시 파일을 `.ipynb_checkpoints`라는 폴더에 저장합니다. 저장 공간이 부족하거나 `.ipynb_checkpoint`라는 디렉터리에 이상한 오류가 발생하는 경우 이 블록을 실행하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir\n",
    "    test = [model_storage_dir, repo_storage_dir]\n",
    "except NameError as e:\n",
    "    print(\"변수에 문제가 있습니다.\")\n",
    "    print(\"첫 번째 블록으로 돌아가서 설정이 올바른지 확인한 다음 셀을 실행하세요.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "import subprocess\n",
    "!find /notebooks/ -type d -name .ipynb_checkpoints -type d -exec rm -rv {} +\n",
    "s = subprocess.run(f'find \"{repo_storage_dir}\" -type d -name .ipynb_checkpoints -exec rm -rv {{}} +', shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 저장 공간 초기화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`/notebooks/`, `/storage/`, `model_storage_dir`, `repo_storage_dir`에 있는 모든 파일이 삭제됩니다. 저장 공간이 부족해 노트북을 삭제하고 싶지 않은 경우에 사용하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the lines below to run this block. You can highlight the lines and do ctrl + /\n",
    "# %store -r model_storage_dir repo_storage_dir\n",
    "# try:\n",
    "#     test = [model_storage_dir, repo_storage_dir]\n",
    "# except NameError as e:\n",
    "#     print(\"There is an issue with your variables.\")\n",
    "#     print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "#     print('Error:', e)\n",
    "#     import sys\n",
    "#     sys.exit(1)\n",
    "# !rm -rf /storage/*\n",
    "# !mv /notebooks/*.ipynb / # move the notebook out of the directory before we nuke it\n",
    "# !rm -rf /notebooks/*\n",
    "# !mv /*.ipynb /notebooks/ # move it back\n",
    "# !rm -rf {model_storage_dir}\n",
    "# !rm -rf {repo_storage_dir}"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
